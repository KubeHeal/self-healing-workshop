= Module 0: Introduction & Architecture

== Overview

Before diving into hands-on exercises, let's understand how the Self-Healing Platform works. This module covers the architecture, key components, and the hybrid approach that combines deterministic automation with AI-driven analysis.

== What is the Self-Healing Platform?

The **OpenShift AI Ops Self-Healing Platform** is a production-ready AIOps solution that:

* ğŸ¤– **Hybrid Approach**: Combines deterministic automation (rule-based) with AI-driven analysis (ML models)
* ğŸ”§ **Self-Healing**: Automatically detects and remediates common cluster issues
* ğŸ“Š **ML-Powered**: Uses Isolation Forest, LSTM models for anomaly detection
* ğŸš€ **OpenShift Native**: Built on Red Hat OpenShift AI, KServe, Tekton, ArgoCD
* ğŸ’¬ **Natural Language Interface**: Chat with your cluster via OpenShift Lightspeed

== The Hybrid Architecture

The platform uses a **hybrid deterministic-AI self-healing approach**:

[source]
----
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Self-Healing Platform                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Coordination Engine (Go REST API)                          â”‚
â”‚  â”œâ”€ Conflict Resolution                                     â”‚
â”‚  â”œâ”€ Priority Management                                     â”‚
â”‚  â””â”€ Action Orchestration                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Deterministic Layer    â”‚    AI-Driven Layer               â”‚
â”‚  â”œâ”€ Machine Config      â”‚    â”œâ”€ Anomaly Detection          â”‚
â”‚  â”‚  Operator            â”‚    â”‚  (Isolation Forest, LSTM)   â”‚
â”‚  â”œâ”€ Known Remediation   â”‚    â”œâ”€ Root Cause Analysis        â”‚
â”‚  â”‚  Procedures          â”‚    â”œâ”€ Predictive Analytics       â”‚
â”‚  â””â”€ Rule-Based Actions  â”‚    â””â”€ Adaptive Responses         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Shared Observability Layer (Prometheus, AlertManager)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
----

=== Why Hybrid?

[cols="1,2,2"]
|===
|Approach |Strengths |Weaknesses

|**Deterministic Only**
|Fast, predictable, well-tested
|Can't handle novel issues

|**AI Only**
|Adapts to new patterns
|May be slow, unpredictable

|**Hybrid (Our Approach)**
|Best of both worlds
|More complex to build
|===

The Coordination Engine decides which layer handles each issue:

* **Known issues** â†’ Deterministic layer (fast, reliable)
* **Novel/complex issues** â†’ AI layer (adaptive, intelligent)
* **Conflicts** â†’ Coordination Engine resolves priority

== Platform Components

=== 1. OpenShift Lightspeed

**What it is**: AI assistant integrated into the OpenShift console

**What it does**:

* Answers questions about your cluster in natural language
* Triggers ML-powered analysis and predictions
* Initiates automated remediation with your approval

**Access**: Click the sparkle icon âœ¨ in the OpenShift console header

=== 2. MCP Server (Go)

**What it is**: Model Context Protocol server connecting Lightspeed to platform tools

**What it does**:

* Exposes 7 tools that Lightspeed can call
* Translates natural language intents to API calls
* Returns structured responses for Lightspeed to format

**MCP Tools Available**:
[source]
----
1. get-cluster-health    â†’ Check namespace status, pods, models
2. list-pods             â†’ Query pods with filtering
3. analyze-anomalies     â†’ Call ML models for detection
4. trigger-remediation   â†’ Apply fixes via Coordination Engine
5. list-incidents        â†’ Query historical incidents
6. get-model-status      â†’ Check KServe InferenceService health
7. list-models           â†’ List available ML models
----

=== 3. Coordination Engine (Go)

**What it is**: REST API service orchestrating remediation workflows

**What it does**:

* Receives anomaly detection requests
* Queries Prometheus for current metrics
* Calls KServe ML models for predictions
* Applies remediation actions to the cluster
* Tracks incidents and resolution history

**API Endpoints**:
[source]
----
GET  /health           â†’ Health check
POST /api/v1/detect    â†’ Detect anomalies
POST /api/v1/remediate â†’ Apply remediation
GET  /api/v1/incidents â†’ List incidents
GET  /metrics          â†’ Prometheus metrics
----

=== 4. KServe ML Models

**What they are**: Machine learning models served via KServe InferenceService

**Models deployed**:

[cols="1,2,2"]
|===
|Model |Purpose |Notebook

|`anomaly-detector`
|Detects unusual patterns in metrics
|`01-isolation-forest-implementation.ipynb`

|`predictive-analytics`
|Forecasts future resource usage
|`05-predictive-analytics-kserve.ipynb`
|===

**Key Point**: These models are trained on **YOUR cluster's data**. Predictions reflect your workload patterns, not generic benchmarks.

=== 5. Jupyter Workbench

**What it is**: JupyterLab environment for ML development

**What it contains**:

* Training notebooks for all ML models
* Utility functions for Prometheus queries
* Integration code for Coordination Engine
* Persistent storage for models and data

**Access**: Via OpenShift AI console or direct URL

=== 6. ArgoCD (GitOps)

**What it is**: GitOps deployment via Validated Patterns framework

**What it does**:

* Manages all platform components declaratively
* Syncs from Git repository automatically
* Provides drift detection and rollback

== Data Flow

Let's trace what happens when you ask Lightspeed a question:

[source]
----
You: "Predict CPU at 3 PM"
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Lightspeed    â”‚ â—„â”€â”€â”€ Natural language understanding
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ MCP protocol
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MCP Server    â”‚ â—„â”€â”€â”€ Routes to correct tool
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ REST API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Coordination   â”‚
â”‚    Engine       â”‚ â—„â”€â”€â”€ Orchestrates the workflow
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚Prometheâ”‚ â”‚KServe â”‚ â—„â”€â”€â”€ Get metrics, call ML model
â”‚  us   â”‚ â”‚ Model â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Lightspeed    â”‚ â—„â”€â”€â”€ Formats response
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
You: "CPU: 74.5% at 3 PM (85% confidence)"
----

== Why Cluster-Specific Training Matters

The ML models are trained specifically for **YOUR cluster**:

* **Your 3 PM is different from our 3 PM**: A retail cluster spikes at lunch, financial services at market open
* **Workload fingerprints are unique**: Your apps' memory patterns, CPU bursts, scaling behaviors
* **Anomaly baselines are contextual**: "Normal" for your cluster might be "abnormal" for another

=== Training Pipeline

[source]
----
Prometheus Metrics â”€â”€â–º Jupyter Notebook â”€â”€â–º Trained Model â”€â”€â–º KServe
     (your data)        (automated via       (your patterns)   (inference)
                         Tekton pipeline)
----

Models retrain automatically (weekly by default) to capture evolving patterns.

== Workshop Environment

Your pre-deployed environment includes:

[cols="2,3,2"]
|===
|Component |Service |Namespace

|OpenShift Lightspeed
|AI assistant in console
|`openshift-lightspeed`

|MCP Server
|`mcp-server:8080`
|`{namespace}`

|Coordination Engine
|`coordination-engine:8080`
|`{namespace}`

|Anomaly Detector
|`anomaly-detector-predictor:8080`
|`{namespace}`

|Predictive Analytics
|`predictive-analytics-predictor:8080`
|`{namespace}`

|Jupyter Workbench
|`self-healing-workbench`
|`{namespace}`
|===

== Verify Your Environment

Let's verify everything is running:

[tabs]
====
OpenShift Console::
+
. Open the OpenShift Console
. Navigate to **Workloads â†’ Pods**
. Select namespace: `{namespace}`
. Verify these pods are Running:
** `coordination-engine-*`
** `mcp-server-*`
** `anomaly-detector-predictor-*`
** `predictive-analytics-predictor-*`
** `self-healing-workbench-0`

CLI::
+
[source,bash,role=execute,subs="attributes+"]
----
oc get pods -n {namespace}
----
+
Expected output:
+
[source]
----
NAME                                         READY   STATUS    RESTARTS   AGE
coordination-engine-xxx                      1/1     Running   0          2h
mcp-server-xxx                               1/1     Running   0          2h
anomaly-detector-predictor-xxx               2/2     Running   0          2h
predictive-analytics-predictor-xxx           2/2     Running   0          2h
self-healing-workbench-0                     2/2     Running   0          2h
----

Lightspeed::
+
. Click the **Lightspeed icon** (âœ¨) in the console header
. Type: `What's the health of the {namespace} namespace?`
. If you get a response with component status, everything is working!
====

== Key Concepts Summary

[cols="1,3"]
|===
|Concept |Description

|**Hybrid Approach**
|Deterministic + AI layers working together

|**Coordination Engine**
|Central orchestrator that routes issues to the right layer

|**MCP (Model Context Protocol)**
|Standard protocol connecting LLMs to external tools

|**KServe**
|Kubernetes-native model serving infrastructure

|**Cluster-Specific Training**
|ML models learn YOUR cluster's patterns
|===

== Next Steps

Now that you understand the architecture, let's get hands-on!

In **xref:module-01.adoc[Module 1: ML Model Training with Tekton]**, you'll:

* Train anomaly detection models manually
* Explore different data sources (Prometheus vs synthetic)
* Understand the automated training pipeline
* Monitor training runs and validate models

---

[TIP]
====
**Architecture Reference**: For detailed architectural decisions, see the https://github.com/KubeHeal/openshift-aiops-platform/tree/main/docs/adrs[ADRs (Architectural Decision Records)] in the platform repository.
====
