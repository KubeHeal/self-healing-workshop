= Module 1: ML Model Training with Tekton

== Overview

This module demonstrates how to train and deploy machine learning models using Tekton pipelines. Automated model training ensures models stay current with cluster behavior, improving prediction accuracy and anomaly detection reliability.

**What you'll learn:**

* Train models manually with custom time windows
* Schedule automated weekly retraining
* Integrate real Prometheus metrics with synthetic data
* Validate model health before deployment
* Add your own custom models

== Quick Start: Train a Model

=== Manual Training with Default Settings (24h Data)

Train the anomaly detector with 24 hours of recent data:

[source,bash,role=execute]
----
oc create -f - <<EOF
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  generateName: train-anomaly-detector-
  namespace: {namespace}
spec:
  pipelineRef:
    name: model-training-pipeline
  params:
    - name: model-name
      value: "anomaly-detector"
    - name: notebook-path
      value: "notebooks/02-anomaly-detection/01-isolation-forest-implementation.ipynb"
    - name: data-source
      value: "prometheus"
    - name: training-hours
      value: "24"
    - name: inference-service-name
      value: "anomaly-detector"
    - name: git-url
      value: "{platform_repo}.git"
    - name: git-ref
      value: "main"
  timeout: 30m
EOF
----

Monitor the training progress:

[source,bash,role=execute]
----
# Watch pipeline execution
tkn pipelinerun logs -f -n {namespace}
----

[source,bash,role=execute]
----
# Check training job status
oc get notebookvalidationjobs -n {namespace}
----

[source,bash,role=execute]
----
# View model file
oc exec -n {namespace} deployment/model-troubleshooting-utilities -- \
  ls -lh /mnt/models/anomaly-detector/
----

=== Manual Training with Custom Time Window

Train the predictive analytics model with 30 days of data for capturing seasonal patterns:

[source,bash,role=execute]
----
oc create -f - <<EOF
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  generateName: train-predictive-analytics-
  namespace: {namespace}
spec:
  pipelineRef:
    name: model-training-pipeline
  params:
    - name: model-name
      value: "predictive-analytics"
    - name: notebook-path
      value: "notebooks/02-anomaly-detection/05-predictive-analytics-kserve.ipynb"
    - name: data-source
      value: "prometheus"
    - name: training-hours
      value: "720"
    - name: inference-service-name
      value: "predictive-analytics"
    - name: git-url
      value: "{platform_repo}.git"
    - name: git-ref
      value: "main"
  timeout: 45m
EOF
----

=== GPU-Accelerated Training with NotebookValidationJob

For faster training, use GPU resources:

[source,bash,role=execute]
----
oc create -f - <<'EOF'
apiVersion: mlops.mlops.dev/v1alpha1
kind: NotebookValidationJob
metadata:
  name: train-predictive-gpu
  namespace: {namespace}
  labels:
    model-name: predictive-analytics
spec:
  notebook:
    git:
      ref: main
      url: {platform_repo}.git
    path: notebooks/02-anomaly-detection/05-predictive-analytics-kserve.ipynb
  podConfig:
    containerImage: image-registry.openshift-image-registry.svc:5000/{namespace}/notebook-validator:latest
    env:
    - name: DATA_SOURCE
      value: prometheus
    - name: PROMETHEUS_URL
      value: https://prometheus-k8s.openshift-monitoring.svc:9091
    - name: TRAINING_HOURS
      value: "168"
    - name: MODEL_NAME
      value: predictive-analytics
    nodeSelector:
      nvidia.com/gpu.present: "true"
    resources:
      limits:
        cpu: "4"
        memory: 8Gi
        nvidia.com/gpu: "1"
      requests:
        cpu: "2"
        memory: 4Gi
        nvidia.com/gpu: "1"
    serviceAccountName: self-healing-workbench
    tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
    volumeMounts:
    - mountPath: /mnt/models
      name: model-storage
    volumes:
    - name: model-storage
      persistentVolumeClaim:
        claimName: gpu-training-pvc
  timeout: 45m
EOF
----

[NOTE]
====
GPU nodes may not have CephFS drivers. Use `gpu-training-pvc` (GP3 storage class) instead of `model-storage-pvc` (CephFS) for GPU-accelerated training. Copy the model to CephFS after training completes.
====

== Training Time Windows

Choose the appropriate time window based on your use case:

[cols="1,1,2,2"]
|===
|Duration |Hours |Use Case |Example

|**1 day**
|24
|Quick iteration, development, testing
|Testing notebook changes

|**1 week**
|168
|Weekly retraining, production anomaly detection
|Anomaly detector scheduled training

|**30 days**
|720
|Initial training, seasonal patterns, forecasting
|Predictive analytics scheduled training
|===

**Recommended defaults:**

* **Anomaly Detector**: 168h (1 week) - Captures weekly patterns without excessive noise
* **Predictive Analytics**: 720h (30 days) - Captures monthly trends and seasonality

== Data Sources

The platform supports three data source modes for model training:

=== Synthetic Data (`DATA_SOURCE=synthetic`)

**Use case**: Development, testing, CI/CD, when Prometheus is unavailable

* ✅ Fast and reproducible
* ✅ Known anomaly labels for validation
* ✅ No external dependencies
* ⚠️ May not capture real cluster patterns

[source,yaml]
----
params:
  - name: data-source
    value: "synthetic"
----

=== Prometheus Data (`DATA_SOURCE=prometheus`)

**Use case**: Production training with real cluster metrics

* ✅ Real cluster behavior patterns
* ✅ Adapts to actual workload characteristics
* ✅ Improves model accuracy
* ⚠️ Requires Prometheus access
* ⚠️ Real anomalies are rare (<1%)

[source,yaml]
----
params:
  - name: data-source
    value: "prometheus"
----

Training notebooks automatically:

. Fetch real metrics from Prometheus (80% of data)
. Inject synthetic anomalies (20% of data) for balanced training
. Combine datasets for robust model training

=== Hybrid Data (`DATA_SOURCE=hybrid`)

**Use case**: Staging, validation, best of both worlds

* ✅ 50% Prometheus + 50% synthetic
* ✅ Balanced representation
* ✅ Good for validation environments

[source,yaml]
----
params:
  - name: data-source
    value: "hybrid"
----

[TIP]
====
**Recommendation**: Use `prometheus` mode for production scheduled training to ensure models learn real cluster patterns.
====

== Automated Scheduled Training

The platform automatically retrains models weekly via CronJobs:

=== Anomaly Detector (Weekly, Sunday 2 AM UTC)

[source,bash,role=execute]
----
# View CronJob configuration
oc get cronjob weekly-anomaly-detector-training -n {namespace} -o yaml
----

[source,bash,role=execute]
----
# View recent training runs
oc get pipelineruns -n {namespace} -l model-name=anomaly-detector
----

[source,bash,role=execute]
----
# Check latest training job
tkn pipelinerun logs -n {namespace} $(oc get pipelinerun -n {namespace} \
  -l model-name=anomaly-detector --sort-by=.metadata.creationTimestamp -o name | tail -1)
----

=== Predictive Analytics (Weekly, Sunday 3 AM UTC)

[source,bash,role=execute]
----
# View CronJob configuration
oc get cronjob weekly-predictive-analytics-training -n {namespace} -o yaml
----

[source,bash,role=execute]
----
# View recent training runs
oc get pipelineruns -n {namespace} -l model-name=predictive-analytics
----

== Monitoring Training Runs

=== Check Pipeline Status

[source,bash,role=execute]
----
# List all pipeline runs
tkn pipelinerun list -n {namespace}
----

[source,bash,role=execute]
----
# Watch specific run (replace with actual name)
tkn pipelinerun logs train-anomaly-detector-abc123 -f -n {namespace}
----

=== Verify Model Deployment

[source,bash,role=execute]
----
# Check InferenceService status
oc get inferenceservice anomaly-detector -n {namespace}
----

[source,bash,role=execute]
----
# Check predictor pod status
oc get pods -l serving.kserve.io/inferenceservice=anomaly-detector \
  -n {namespace}
----

[source,bash,role=execute]
----
# View model file details
oc exec -n {namespace} deployment/model-troubleshooting-utilities -- \
  ls -lh /mnt/models/anomaly-detector/model.pkl
----

=== Test Model Endpoint

[source,bash,role=execute]
----
# Get predictor pod IP
PREDICTOR_IP=$(oc get pod -n {namespace} \
  -l serving.kserve.io/inferenceservice=anomaly-detector \
  -o jsonpath='{.items[0].status.podIP}')

# Test anomaly detector
curl -X POST http://${PREDICTOR_IP}:8080/v1/models/anomaly-detector:predict \
  -H 'Content-Type: application/json' \
  -d '{"instances": [[0.5, 0.6, 0.4, 0.3, 0.8]]}'
----

== Hands-On Exercise: Train Your First Model

Let's train the anomaly detector with a short training window:

=== Step 1: Start Training

[source,bash,role=execute]
----
oc create -f - <<EOF
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  generateName: workshop-train-
  namespace: {namespace}
  labels:
    workshop: self-healing
spec:
  pipelineRef:
    name: model-training-pipeline
  params:
    - name: model-name
      value: "anomaly-detector"
    - name: notebook-path
      value: "notebooks/02-anomaly-detection/01-isolation-forest-implementation.ipynb"
    - name: data-source
      value: "synthetic"
    - name: training-hours
      value: "24"
    - name: inference-service-name
      value: "anomaly-detector"
    - name: git-url
      value: "{platform_repo}.git"
    - name: git-ref
      value: "main"
  timeout: 15m
EOF
----

=== Step 2: Watch the Training

[source,bash,role=execute]
----
# Get the pipeline run name
PIPELINERUN=$(oc get pipelinerun -n {namespace} -l workshop=self-healing \
  --sort-by=.metadata.creationTimestamp -o name | tail -1)

echo "Watching: $PIPELINERUN"
tkn pipelinerun logs $PIPELINERUN -f -n {namespace}
----

=== Step 3: Verify the Model

Once training completes:

[source,bash,role=execute]
----
# Check InferenceService
oc get inferenceservice anomaly-detector -n {namespace}
----

Expected output:
[source]
----
NAME               URL                                              READY
anomaly-detector   http://anomaly-detector-predictor-default.svc    True
----

== Troubleshooting

=== Model Training Fails

**Symptoms**: Pipeline run fails, NotebookValidationJob shows error

**Diagnosis**:
[source,bash,role=execute]
----
# Check pipeline logs
tkn pipelinerun logs <pipelinerun-name> -f -n {namespace}

# Check NotebookValidationJob status
oc get notebookvalidationjobs -n {namespace}
oc describe notebookvalidationjob <job-name> -n {namespace}
----

**Common causes**:

* Insufficient memory (increase `memoryLimit`)
* Prometheus unavailable (check connectivity)
* Git repository inaccessible (verify URL)
* Notebook syntax errors (test locally first)

=== Model Won't Load

**Symptoms**: Predictor pod crashes, OOMKilled, CrashLoopBackOff

**Diagnosis**:
[source,bash,role=execute]
----
# Check predictor pod logs
oc logs -n {namespace} \
  -l serving.kserve.io/inferenceservice=anomaly-detector

# Check model file exists
oc exec -n {namespace} deployment/model-troubleshooting-utilities -- \
  ls -lh /mnt/models/anomaly-detector/
----

**Common causes**:

* Model file corrupted (retrain model)
* Model too large (increase predictor memory)
* Incompatible sklearn version (check runtime image)

=== Prometheus Data Issues

**Symptoms**: Training falls back to synthetic data

[IMPORTANT]
====
OpenShift Prometheus requires **bearer token authentication** over HTTPS port 9091.
====

**Diagnosis**:
[source,bash,role=execute]
----
# Check Prometheus accessibility with bearer token
oc exec -n {namespace} deployment/model-troubleshooting-utilities -- sh -c '
TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
curl -sk -H "Authorization: Bearer $TOKEN" \
  "https://prometheus-k8s.openshift-monitoring.svc:9091/api/v1/status/config" | head -c 200
'
----

== Summary

In this module, you learned:

* ✅ How to train models manually with PipelineRuns
* ✅ Different training time windows and when to use them
* ✅ Data sources: synthetic, prometheus, hybrid
* ✅ How to monitor training and verify deployments
* ✅ Troubleshooting common training issues

== Next Steps

Now that you have trained models, let's use them!

In **xref:module-02.adoc[Module 2: End-to-End Self-Healing with Lightspeed]**, you'll:

* Chat with your cluster using natural language
* Deploy sample applications
* Predict future resource usage
* Break things on purpose and watch AI fix them!
